<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="./../../style/style.css" />
    <title>Face Recognition App</title>

    <script defer src="./../../script/face-api.js"></script>
    <script defer src="./../../script/script-dashboard.js"></script>
</head>
<body onload="">
    <script src="./../component/navbar.js"></script>

    <main>
        <p class="title">INPUT DATA TRAINING: <span></span></p>

        <div class="container">
            <div class="cam-container">
                <video id="cam" width="320" height="240" playsinline autoplay muted></video>
                <button id="btnStart" onclick="startCam()" class="btn btnGreen">Buka Kamera</button>
                <button id="btnTakePict" onclick="takePicture()" class="hide">Ambil Gambar</button>
                <!-- <button onclick="takePicture()" class="btn btnGrey">Ambil Gambar</button> -->
            </div>

            <div class="prev-container">
                <div id="img-container" class="img-container">
                    <!-- <p>Total: <span>0</span></p> -->
                    <!-- <p>Preview</p> -->
                </div>
                <button id="btnProcessImg" onclick="processImg()" class="btnDisable">Proses</button>
            </div>
        </div>
    </main>

    <!-- <script src="./../../script/face-api.js"></script> -->
    <script>
        let label, uid
        let count = 0
        let imgElement = []
        let faceDescriptors

        const video = document.getElementById('cam')
        const v_width = video.width
        const v_height = video.height
        const btnStart = document.getElementById('btnStart')
        const btnTakePict = document.getElementById('btnTakePict')
        const btnProcessImg = document.getElementById('btnProcessImg')
        const imgContainer = document.getElementById('img-container')
        
        let canvas = document.createElement('canvas')
        let ctx = canvas.getContext('2d')
        canvas.width = v_width
        canvas.height = v_height

        const model_url = './../../models'

        window.onload = function() {
            try {
                var url_string = (window.location.href)
                var url = new URL(url_string)
                
                label = url.searchParams.get('u')
                uid = url.searchParams.get('i')

                document.querySelector('span').innerText = label
            } catch(err) {
                console.log(err)
            }
        }

        async function startCam() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: false,
                    video: {width: v_width, height: v_height}
                })
                handleSuccess(stream)
                
                btnStart.setAttribute('class', 'hide')
                btnTakePict.setAttribute('class', 'btn btnGreen')
                // btnProcessImg.setAttribute('class', 'btn btnGreen')
            } catch(err) { console.log(err) }
        }

        function handleSuccess(stream) {
            window.stream = stream
            video.srcObject = stream
        }

        function takePicture() {
            ctx.drawImage(video, 0, 0)
            const dataUrl = canvas.toDataURL('image/png')

            const image = document.createElement('img')
            image.src = dataUrl
            image.setAttribute('onclick', 'remove(event)')
            
            imgElement.push(image)
            imgContainer.insertAdjacentElement('beforeend', image)

            ctx.clearRect(0, 0, v_width, v_height)
            
            count++

            if (count === 1) {
                btnProcessImg.setAttribute('class', 'btn btnGreen')
            }
        }

        function remove(e) {
            e.target.remove()
            count--

            if (count < 1) {
                btnProcessImg.setAttribute('class', 'btnDisable')
            }
        }

        async function processImg() {
            if (!faceapi.nets.ssdMobilenetv1._params) {
                // Promise.all([
                await faceapi.nets.faceRecognitionNet.loadFromUri(model_url)
                await faceapi.nets.faceLandmark68Net.loadFromUri(model_url)
                await faceapi.nets.ssdMobilenetv1.loadFromUri(model_url)
                console.log('Model loaded!')
                // ])
                // .then(console.log('Model loaded'))
            }
            
            // else {
            faceDescriptors = await loadLabeledImages()
            console.log(faceDescriptors)
            
            fetch(`http://127.0.0.1:3001/model/descriptor`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ id: uid, descriptor: faceDescriptors })
            })
            .then(res => res.ok ? window.location.href('/pages/dashboard/users.html') : console.log('Error'))
            .catch(err => console.log(err))
            // }
        }

        async function loadLabeledImages() {
            const descriptors = []

            for (let i = 0; i < imgElement.length; i++) {
                const img = await faceapi.fetchImage(imgElement[i].src)
                const detection = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor()
                descriptors.push(detection.descriptor)
            }

            return new faceapi.LabeledFaceDescriptors(label, descriptors)
        }
    </script>
</body>
</html>